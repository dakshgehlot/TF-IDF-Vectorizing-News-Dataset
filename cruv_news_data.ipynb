{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c65df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import re\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7684dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      After reaching his hotel in the city, RM revea...\n",
      "1      RM aka Kim Namjoon was the first member to joi...\n",
      "2      Billie Eilish's concert was held in Seoul, Sou...\n",
      "3      BTS ARMY y'all would be missing the members a ...\n",
      "4      BTS member Kim Seokjin aka Jin has the capacit...\n",
      "                             ...                        \n",
      "805    BTS has conquered the world with their group r...\n",
      "806    Today marks 700 days since BTS' worldwide hand...\n",
      "807    BTS' youngest member Jungkook came online on W...\n",
      "808    BTS' eldest member Jin has shared pictures and...\n",
      "809    After a lot of teasing, Benny Blanco’s collabo...\n",
      "Name: content, Length: 810, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Loading the csv using pandas\n",
    "df = pd.read_csv(\"news.csv\")\n",
    "df = df.fillna(method = \"ffill\")\n",
    "contents = df[\"content\"]\n",
    "\n",
    "# deleting title column from dataframe\n",
    "df = df.drop('title', axis=1)\n",
    "\n",
    "# Renaming content column to original content\n",
    "df = df.rename(columns={'content': 'original_content'})\n",
    "\n",
    "# Inserting new columns in the dataframe\n",
    "df.insert(1, 'new_content', '')\n",
    "df.insert(2, 'removed_lines', '')\n",
    "df.insert(3, 'top_sentence_tf_idf', '')\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0260f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, content in enumerate(contents):\n",
    "    \n",
    "    # using regex to replace bad characters with their actual conterparts.\n",
    "    content = re.sub(r\"â€™|â€˜|â€|â€œ\", \"'\", content)\n",
    "    content = re.sub(r\"Â\", \"\", content)\n",
    "    content = re.sub(r\"&nbsp;\", \" \", content)\n",
    "    \n",
    "    # Some content data doesn't have periods \".\" (due to web scraping issues probably) \n",
    "    # so that can't be used for splitting. They have double whitespaces (\"  \") instead\n",
    "    content = content.replace(\"  \", \". \")\n",
    "    \n",
    "    # Split the data into individual sentences\n",
    "    sentences = content.split(\".\")\n",
    "\n",
    "    # Apply a tf-idf vectorizer to the sentences to calculate the tf-idf scores of each word in the sentence\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Calculate the tf-idf score of each sentence by summing the tf-idf scores of all the words in the sentence\n",
    "    sentence_scores = tfidf_matrix.sum(axis=1)\n",
    "\n",
    "    # Rank the sentences based on their tf-idf scores, from highest to lowest\n",
    "    ranked_sentences = sorted(((score, index) for index, score in enumerate(sentence_scores)), reverse=True)\n",
    "    \n",
    "    # Select the top 10% sentences as the most important sentences in the document\n",
    "    top_sentences_count = ceil(len(sentences) * 0.1)\n",
    "    top_sentences = sorted([sentences[i] for score, i in ranked_sentences[:top_sentences_count]])\n",
    "    \n",
    "    # Getting the top tf-idf scores\n",
    "    top_scores = sorted([score for score, i in ranked_sentences[:top_sentences_count]])\n",
    "    curr_top_tfidf = sorted(top_scores, reverse = True)[0]\n",
    "    curr_top_tfidf = curr_top_tfidf[0,0]\n",
    "    \n",
    "    # Selecting the remaining sentences\n",
    "    remaining_sentences = sorted([sentences[i] for score, i in ranked_sentences[top_sentences_count:]])\n",
    "\n",
    "    # Generate a summary of the text using the selected sentences\n",
    "    summary = '. '.join(top_sentences)\n",
    "    \n",
    "    # Join all the remaining sentences to get the removed lines\n",
    "    removed_content = \". \".join(remaining_sentences)\n",
    "    \n",
    "    # Omitting the extra periods and spaces at the starting of the texts\n",
    "    while summary.startswith('.') or summary.startswith(' ') or summary.startswith('\\n'):\n",
    "        summary = summary[1:]\n",
    "    \n",
    "    while removed_content.startswith('.') or removed_content.startswith(' ') or removed_content.startswith('\\n'):\n",
    "        removed_content = removed_content[1:]\n",
    "    \n",
    "    # Inserting the new data into the dataframe\n",
    "    df.loc[i, 'new_content'] = summary\n",
    "    df.loc[i, 'removed_lines'] = removed_content\n",
    "    df.loc[i, 'top_sentence_tf_idf'] = curr_top_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "088d31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the final cleaned dataset from the dataframe\n",
    "df.to_csv('cleaned_news_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66f644f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file for splitting\n",
    "data = pd.read_csv('cleaned_news_set.csv')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Save the training and testing sets to CSV files\n",
    "train.to_csv('train_set.csv', index=False)\n",
    "test.to_csv('test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777d98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
